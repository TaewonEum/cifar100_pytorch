{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315b1fb7-2868-4922-90ed-25b75dc82354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #torch 패키지에는 다차원 데이터구조 즉 Tensor가 포함되어있고, 텐서에 대해 연산을 하는 다양한 함수가 포함되어있음.\n",
    "import torchvision #torchvision 패키지에는 데이터 셋, 이미지 리사이즈, 이미지 텐서 변환, 이미지 정규화등을 할 수 있고, VGGnet과 같은 이미지 분류 모델도 포함하고있음 \n",
    "#torchvision.dataset.데이터명(),torchvision.model.VGG등 \n",
    "import torchvision.transforms as transforms #이미지 크기를 맞춰주거나 텐서로 변환 정규화등을 실행\n",
    "import torch.nn as nn #deep learning model에 필요한 모듈이 모아져있는 패키지, 신경망을 구축하기 위한 데이터 구조나 레이어 정의\n",
    "#ex) ReLU와 같은 활성화함수, nn.CrossEntropyLoss()와 같은 손실함수가 포함되어있음\n",
    "import torch.nn.functional as F #nn과 같은 모듈이 모아져 있음, functional은 함수, nn은 클래스임\n",
    "#torch.nn은 인스턴트화를 시켜야함->저장하여 활용이 가능하다\n",
    "#torch.nn.functional은 인스턴트화 시켜줄 필요없이 버로 입력값을 받아 수행가능함\n",
    "import torch.optim as optim #학습에 관련된 optimizing method가 있는 패키지\n",
    "#torch.optim 다양한 최적화 알고리즘을 구현하는 패키지이다. 확률적 경사하강법을 중심으로한 파라미터 최적화 알고리즘 구현\n",
    "import matplotlib.pyplot as plt #시각화 패키지\n",
    "import numpy as np #메트릭스, 백터, 배열등 계산."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a592f86-f47c-45cd-ba56-0c9b6c8e82a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e7e6dc2e30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 고정\n",
    "torch.manual_seed(42)\n",
    "####seed를 고정해주게되면 학습할때마다 훈련데이터가 계속 바뀌면서 모델 성능이 계속변화하는 등, 혼란이 있을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "789efb20-000d-43d5-aa7a-c16a95353285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntraindata=50000, class=100\\ntestdata=10000\\ndata shape=32x32x3\\nmean=array([0.50707516, 0.48654887, 0.44091784])\\narray([0.26733429, 0.25643846, 0.27615047])\\nmean=0.478\\nstd=0.26\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########preparing data\n",
    "'''\n",
    "traindata=50000, class=100\n",
    "testdata=10000\n",
    "data shape=32x32x3\n",
    "mean=array([0.50707516, 0.48654887, 0.44091784])\n",
    "array([0.26733429, 0.25643846, 0.27615047])\n",
    "mean=0.478\n",
    "std=0.26\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5e80bda-0346-4c68-9f82-cba1abf89a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e7e6dc2e30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 고정\n",
    "torch.manual_seed(42)\n",
    "####seed를 고정해주게되면 학습할때마다 훈련데이터가 계속 바뀌면서 모델 성능이 계속변화하는 등, 혼란이 있을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e063f0b-b966-4a74-9582-445cc9900c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,0.5,0.5),(0.5, 0.5, 0.5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9af9667-72ba-4c91-b84d-76d4411b5e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data=torchvision.datasets.CIFAR100(root='./data', train=True, download=True,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81d4fa2b-1a87-4f8b-ab06-08ef53930a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader=trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True, num_workers=2) #데이터가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "491a28cc-cdf3-4d83-812e-c948aa39581a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR100\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(trainloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "461e4b4c-c5e9-4563-b5f8-4d8349c2a6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_data = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92e949f9-3ab0-41bb-9a44-ee200af679e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False, num_workers=2) \n",
    "#test data는 shuffle X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fb3182c-0b1d-424f-8991-8076a6d9561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지를 보여주기 위한 함수\n",
    "def imshow(img) :\n",
    "  img = img*0.5+0.5 #unnormalize\n",
    "  npimg = img.numpy()\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "388be96c-7b7f-4dc7-954e-b1cb25d2bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader) #iter(호출가능한객체, 반복을 끝낼값), iter()을 적용햐쥬는 이유 optimizer를 구성하려면 최적화할 매개변수를 포함하는 iterable을 제공해야해서 iter()을 적용하여 iterator데이터 타입으로 생성\n",
    "images, labels = dataiter.next()\n",
    "#iter() 함수로 trainloader에 들어있는 이미지와 라벨을 꺼낼 수 있는 객체를 생성함\n",
    "#next() 함수로 이미지와 데이터 라벨을 꺼내옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9b9b14c-2d32-4fbc-8be2-926b9328220c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4*4*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf3f4e46-75c4-4e9d-ad21-54b04cef43f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module): #신경망을 정의할때 nn.Module을 활용하여 만드는 것이 일반적\n",
    "    def __init__(self): # __init__에서 함수를 정의함, super()를 통해 nn.Module의 다양한 함수들을 \n",
    "        super(Net, self).__init__() #super()를 통해 클래스 상속, super(모델명,self).__init__을 통해 nn.Module을 실행시키는 코드\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3,padding=1) #컨볼루션 레이어->학습가능한 필터로 이루어진 부분, 필터란:이미지의 특징을 찿아내기 위한 공용파라미터\n",
    "        self.batch1=nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2, 2) #2x2, stride=2인 Maxpooling \n",
    "        self.conv2 = nn.Conv2d(32, 32, 3,padding=1)#conv2d(input,output,kernel_size)\n",
    "        self.batch2=nn.BatchNorm2d(32)\n",
    "        self.conv3=nn.Conv2d(32,64,3,padding=1)\n",
    "        self.batch3=nn.BatchNorm2d(64)\n",
    "        self.conv4=nn.Conv2d(64,64,3,padding=1)\n",
    "        self.batch4=nn.BatchNorm2d(64)\n",
    "        self.conv5=nn.Conv2d(64,64,3,padding=1)\n",
    "        self.batch5=nn.BatchNorm2d(64)\n",
    "        self.conv6=nn.Conv2d(64,128,3,padding=1)\n",
    "        self.batch6=nn.BatchNorm2d(128)\n",
    "        self.conv7=nn.Conv2d(128,128,3,padding=1)\n",
    "        self.batch7=nn.BatchNorm2d(128)\n",
    "        self.conv8=nn.Conv2d(128,128,3,padding=1)\n",
    "        self.batch8=nn.BatchNorm2d(128)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4,1024) #nn.Linear(input feature, output feature),선형변환을 적용하는 모듈,최종 이미지 output이 5x5x16의 3차원인데 이를 1차원으로 펼쳐주면 총400개의 입력값이 나오고 120개의 y값으로 반환한다\n",
    "        self.batch_fc1=nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024, 512) #84개의 뉴런을 output으로 선정한 이유는 Lenet-5는 7x12 크기의 bitmap 사진을 분류하였기 때문이다.\n",
    "        self.batch_fc2=nn.BatchNorm1d(512)\n",
    "        self.fc3=nn.Linear(512,256)\n",
    "        self.batch_fc3=nn.BatchNorm1d(256)\n",
    "        self.fc4 = nn.Linear(256, 100) #최종적으로 10개의 라벨을 추출하는 세번째 fully-connected layer\n",
    "        \n",
    "        \n",
    "    def forward(self, x): #forward에서 모델이 어떻게 학습할지 코딩\n",
    "        x = F.relu(self.batch1(self.conv1(x))) #32x32x32\n",
    "        x = self.pool(F.relu(self.batch2(self.conv2(x)))) #16x16x32 pooling 적용\n",
    "        x = F.relu(self.batch3(self.conv3(x))) #16x16x64\n",
    "        x = F.relu(self.batch4(self.conv4(x))) #16x16x64\n",
    "        x = self.pool(F.relu(self.batch5(self.conv5(x)))) #8x8x64 pooling적용\n",
    "        x = F.relu(self.batch6(self.conv6(x))) #8x8x128\n",
    "        x = F.relu(self.batch7(self.conv7(x)))\n",
    "        x = self.pool(F.relu(self.batch8(self.conv8(x)))) #4x4x128 pooling 적용\n",
    "        x = x.view(-1, 128*4*4) #conv layer를 거쳐 나온 최종 데이터=shape torch.Size([4, 16, 5, 5]), 2,3,4번째의 값을 곱한값으로 변환시킴. 첫번째 값은 배치 데이터를 의미하기 때문에 곱해주지않음\n",
    "        # x = torch.flatten(x, 1) #3차원->1차원으로 평탄화작업, flatten을 해주는 이유 분류를 위한 학습 레이어에서는 1차원 데이터로 바꾸어서 학습이 되어야하기 때문이다.\n",
    "        #x=torch.flatten(x,1)\n",
    "        #x.size() #torch.Size([4, 400])\n",
    "        x = F.relu(self.fc1(x)) #fully-connected층(1차원변환데이터를 통해 각 범주에 속할확률구하는 층)+Relu(activation function=분류를위한 데이터 특징강조,비선형) \n",
    "        #배치당 4개의 이미지에 대한 [4,120] Tensor값 추출\n",
    "        x = F.relu(self.fc2(x)) #fully-connected층(1차원변환데이터를 통해 각 범주에속학확률구하는 충)+Relu(activation function=분류를 위한 데이터 특장강조,비선형)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "        \n",
    "net = Net() #여기에 \n",
    "\n",
    "###Relu함수: 활성화 함수중 하나. +/-가 반복되는 신호에서 -흐름을 차단함.\n",
    "###말 그대로 양수면 자기 자신을 반환하고, 음수면 0을 반환한다->출력값의 범위가 넓고 양수인 경우 자기 자신을 그대로 반환하기 때문에, 기울기 소실문제가 발생하지 않음\n",
    "###기존 활성화 함수보다 속도가 매우빠르다\n",
    "##CNN을 두가지로 나누어 본다면\n",
    "##-Convolution/pooling/activation function layer: 이미지를 분할하고 분석하여 특징을 추출하는 layer\n",
    "##pooling: 정보를 유지하며 픽셀의 크기를 줄이는 것\n",
    "##activation function: 모델의 복잡도를 올리기 위해 비선형성 추가\n",
    "##-FC(Fully-connected)/activation function: 이전 레이어 출력을 평탄화(벡터화) 이미지를 분류/예측하는데 가장 적합하게 예측->이미지를 라벨로 분류하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91a7e99d-ec4b-47cd-b62d-595618654e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() #손실함수->예측값과 실제값 비교\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(0.9,0.999)) #optim.Adam(model.parameters(),lr=,) variable 타입의 파라미터들을 iterable 오브젝트로 넣어줘야한다.\n",
    "#optimization gradient(기울기)구해서 가중치 값을 변환시켜\n",
    "#최적의 weight값을 찿는다.\n",
    "#SGD의 원리는 loss함수의 미분을 이용하여 loss를 줄이는것 gradient가 -가 되도록 값을 이동시키면 언젠가 최소값을 찿을 수 있다는 아이디어\n",
    "#SGD적용 속도가 매우빠름.\n",
    "#learning rate=미분값을 얼만큼 이동시킬지->조금씩해야함\n",
    "#momentum=이전 가중치의 업데이트값의 일정 비율을 반영하는 매개변수, batch\n",
    "#betas 각각의 모멘텀 값."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a7e428-ee73-4112-acf1-fdab6747cc6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 91.713\n",
      "[1,  4000] loss: 89.808\n",
      "[1,  6000] loss: 87.902\n",
      "[1,  8000] loss: 85.668\n",
      "[1, 10000] loss: 83.853\n",
      "[1, 12000] loss: 82.700\n",
      "[2,  2000] loss: 80.725\n",
      "[2,  4000] loss: 79.589\n",
      "[2,  6000] loss: 78.653\n",
      "[2,  8000] loss: 77.469\n",
      "[2, 10000] loss: 76.833\n",
      "[2, 12000] loss: 75.583\n",
      "[3,  2000] loss: 73.818\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(8): # 여러번 데이터셋 반복하기\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0): #enumerate 인덱스와 원소 tuple로 반환\n",
    "        # 입력값을 얻습니다. 데이타는 [입력값, 레이블]의 목록입니다.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # 매개변수 변화도를 0으로 만듭니다.\n",
    "        optimizer.zero_grad() #한번 학습이 완료되면, gradient를 0으로 만들어주어야함, 초기화하지 않을시 의도한 방향과 다른방향으로 학습할 가능성\n",
    "        \n",
    "        # 순전파 + 역전파 + 최적화\n",
    "        outputs = net(inputs) #CNN모델 적용부분\n",
    "        loss = criterion(outputs, labels) #loss계산\n",
    "        loss.backward() #backpropogation에서 gradient를 계산, loss값들을 가중치들에 대해서 미분 ex)x가 변화했을때 함수g가 얼마나 변하는지 알 수 있음\n",
    "        optimizer.step() #업데이트할 parameter와 learning rate 들을 step() method를 통해 업데이트 한다\n",
    "        \n",
    "        \n",
    "        # 통계 출력\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999: # 매 2000번 미니배치마다 출력하기\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch+1, i+1, running_loss / 100))\n",
    "            running_loss =0.0\n",
    "            \n",
    "print('Finished Training')\n",
    "\n",
    "PATH = './cifar_net.pth' #저장경로\n",
    "torch.save(net.state_dict(), PATH) #저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a681bd-2f9b-4363-a3b4-2d0932a3fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Loss.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd914d4-be8b-4ff0-a76c-62cfcfe12f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "#iter() 함수로 trainloader에 들어있는 이미지와 라벨을 꺼낼 수 있는 객체를 생성함\n",
    "#next() 함수로 이미지와 데이터 라벨을 꺼내옴\n",
    "# 이미지 출력하기\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(10)))\n",
    "\n",
    "net = Net() #net초기화\n",
    "net.load_state_dict(torch.load(PATH)) #train으로 학습한 모델의 파라미터 불러오기 (dictionary형태로 parameter정보가 포함되어있음)\n",
    "outputs = net(images) #모델적용\n",
    "_, predicted = torch.max(outputs, 1) #예측최대값과 최대값에 인데스를 튜플로 반환,행을 기준으로 최대값 찿음\n",
    "print('Predicted : ', ' '.join('%5s' % classes[predicted[j]] for j in range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b923fd-95df-4f43-b22f-09dad1c92c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad(): #test예측할때는 gradient,context를 비활성화 시켜줌으로써 계산속도 향상시켜줌\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images) #모델적용\n",
    "        _, predicted = torch.max(outputs.data, 1) #행을 기준으로 최대값 찿음\n",
    "        total += labels.size(0) #전체 10000개\n",
    "        correct += (predicted == labels).sum().item() #예측값==실제값 카운트\n",
    "        \n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e9803f-2a9d-4a61-94c4-a8653e912c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images) #모델 적용\n",
    "        _, predictions = torch.max(outputs, 1) #행기준으로 예측 최대값 찿음\n",
    "        for label, prediction in zip(labels, predictions): #zip함수를 통해 (실제값,예측값)형태로 묶음\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cc755e-d93f-4857-a508-ff030ea421ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
